{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0fe7c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1524c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mental health dataset\n",
    "df_text = pd.read_csv(\"dataset/mental_health.csv.zip\")\n",
    "\n",
    "# Add subject IDs (0, 1, 2, â€¦)\n",
    "df_text['subject'] = range(len(df_text))\n",
    "\n",
    "# Load keystroke dataset\n",
    "df_keys = pd.read_csv(\"dataset/DSL-StrongPasswordData.csv\")\n",
    "\n",
    "# Overwrite subject column with sequential numbers\n",
    "df_keys['subject'] = range(len(df_keys))\n",
    "# Example: add fake labels just for testing\n",
    "import numpy as np\n",
    "df_keys['label'] = np.random.randint(0, 2, size=len(df_keys))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "207a1e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject', 'text', 'label_x', 'sessionIndex', 'rep', 'H.period',\n",
      "       'DD.period.t', 'UD.period.t', 'H.t', 'DD.t.i', 'UD.t.i', 'H.i',\n",
      "       'DD.i.e', 'UD.i.e', 'H.e', 'DD.e.five', 'UD.e.five', 'H.five',\n",
      "       'DD.five.Shift.r', 'UD.five.Shift.r', 'H.Shift.r', 'DD.Shift.r.o',\n",
      "       'UD.Shift.r.o', 'H.o', 'DD.o.a', 'UD.o.a', 'H.a', 'DD.a.n', 'UD.a.n',\n",
      "       'H.n', 'DD.n.l', 'UD.n.l', 'H.l', 'DD.l.Return', 'UD.l.Return',\n",
      "       'H.Return', 'label_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Merge safely: keep text + label from mental health dataset\n",
    "df = pd.merge(\n",
    "    df_text[['subject','text','label']],  # only keep subject, text, label\n",
    "    df_keys, \n",
    "    on=\"subject\"\n",
    ")\n",
    "\n",
    "print(df.columns)  # check columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c496f8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject', 'text', 'label', 'sessionIndex', 'rep', 'H.period',\n",
      "       'DD.period.t', 'UD.period.t', 'H.t', 'DD.t.i', 'UD.t.i', 'H.i',\n",
      "       'DD.i.e', 'UD.i.e', 'H.e', 'DD.e.five', 'UD.e.five', 'H.five',\n",
      "       'DD.five.Shift.r', 'UD.five.Shift.r', 'H.Shift.r', 'DD.Shift.r.o',\n",
      "       'UD.Shift.r.o', 'H.o', 'DD.o.a', 'UD.o.a', 'H.a', 'DD.a.n', 'UD.a.n',\n",
      "       'H.n', 'DD.n.l', 'UD.n.l', 'H.l', 'DD.l.Return', 'UD.l.Return',\n",
      "       'H.Return'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Keep the real labels from the text dataset\n",
    "df.rename(columns={'label_x':'label'}, inplace=True)\n",
    "\n",
    "# Drop the fake labels from keystroke dataset\n",
    "df.drop(columns=['label_y'], inplace=True)\n",
    "\n",
    "print(df.columns)  # should now show 'subject', 'text', 'label', plus keystroke features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "915e6af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_text_vec = vectorizer.fit_transform(X_train_text)\n",
    "X_test_text_vec = vectorizer.transform(X_test_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2c5aeb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_hold'] = df[[c for c in df.columns if c.startswith(\"H.\")]].mean(axis=1)\n",
    "df['avg_dd'] = df[[c for c in df.columns if c.startswith(\"DD.\")]].mean(axis=1)\n",
    "df['avg_ud'] = df[[c for c in df.columns if c.startswith(\"UD.\")]].mean(axis=1)\n",
    "X_keys = df[['avg_hold','avg_dd','avg_ud']].values \n",
    "y_keys = df['label'].values\n",
    "scaler = StandardScaler() \n",
    "X_keys_scaled = scaler.fit_transform(X_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c048e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_keys, X_test_keys, y_train_keys, y_test_keys = train_test_split( X_keys_scaled, y_keys, test_size=0.2, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "62b4c355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keystroke Model Accuracy: 0.5102941176470588\n"
     ]
    }
   ],
   "source": [
    "model_keys = LogisticRegression(max_iter=1000) \n",
    "model_keys.fit(X_train_keys, y_train_keys) \n",
    "pred_keys = model_keys.predict(X_test_keys) \n",
    "print(\"Keystroke Model Accuracy:\", accuracy_score(y_test_keys, pred_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1203e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = hstack([X_train_text_vec, X_train_keys])\n",
    "X_test_combined = hstack([X_test_text_vec, X_test_keys])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d4906920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Model Accuracy: 0.9139705882352941\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_combined, y_train)\n",
    "\n",
    "pred = model.predict(X_test_combined)\n",
    "print(\"Combined Model Accuracy:\", accuracy_score(y_test, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "31882d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [[0.87465912 0.12534088]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_text = [\"I feel hopeless and lost\"]\n",
    "sample_text_vec = vectorizer.transform(sample_text)\n",
    "\n",
    "# Example typing features (replace with real values)\n",
    "sample_typing = np.array([[2.0, 4.0, 5.0]])  # avg_hold, avg_dd, avg_ud\n",
    "sample_typing_scaled = scaler.transform(sample_typing)\n",
    "\n",
    "sample_combined = hstack([sample_text_vec, sample_typing_scaled])\n",
    "print(\"Probabilities:\", model.predict_proba(sample_combined))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
